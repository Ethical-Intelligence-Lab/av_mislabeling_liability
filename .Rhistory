df <- rbind(df, df_flipped)
View(df)
colnames(df)[1] <- "ps_index"
colnames(df)[2] <- "paired"
View(df)
View(df)
df |>
group_by(ps_index, level) |>
summarize(
n = n()
)
df |>
group_by(ps_index, level) |>
summarize(
n = n()
) -> check
View(check)
setwd("/Users/jho/Dropbox (Harvard University)/av_mislabeling_liability/e7_tesla_website")
# libraries
library(tidyverse)
library(ggpubr)
library(sjstats)
d <- read_csv("e7_simulated.csv")
View(d)
## ================================================================================================================
##                                 Harvard Business School, Ethical Iopelligence Lab
## ================================================================================================================
##                                DATA ANALYSIS | AV RESPONSIBILITY STUDY | EXPERIMEop 5
## ================================================================================================================
## clear workspace
rm(list = ls())
# libraries
library(sjstats)
library(tidyverse)
library(ggpubr)
library(ggsignif)
# Read full dataset
df <- read_csv("e7_simulated.csv")
# Remove first two rows that were headers
df <- df[-c(1,2),]
View(df)
# Read full dataset
df <- read_csv("e7_simulated.csv")
# Remove first two rows that were headers
df <- df[-c(1,2),]
#==============================================================
# EXCLUSIONS
#==============================================================
df |>
filter(
att_1 == 2,
att_2 == 2,
comp_1 == 2,
comp_2 == 4,
comp_3 == 1
) -> df
View(df)
library(tidyverse)
library(ggpubr)
library(ggsignif)
# Read full dataset
df <- read_csv("e7_simulated.csv")
# Remove first two rows that were headers
df <- df[-c(1,2),]
View(df)
View(df)
#==============================================================
# EXCLUSIONS
#==============================================================
## Failed Attention Checks
df |>
filter(
att_1 == "Paul",
att_2 == "Green") -> df
View(df)
# Read full dataset
df <- read_csv("e7_simulated.csv")
View(df)
unique(df$comp_1)
unique(df$comp_2)
## Comprehension Checks
df |>
filter(
comp_1 == "Different types of vehicles based on how many driving tasks are controlled by humans vs. machines",
comp_2 == "HUMAN, HUMAN, HUMAN, HUMAN"
) -> df
View(df)
#==============================================================
# EXCLUSIONS
#==============================================================
## Failed Attention Checks
df |>
filter(
att_1 == "Paul",
att_2 == "Green") -> df
View(df)
### TODO: REMOVE THIS FOR NON SIMULATED
df <- read_csv("e7_simulated.csv")
View(df)
df <- df[-c(1,2),]
View(df)
c("level_1", "level_2", "hard_1_1", "info_text", "level_3", "gender", "age", "license", "ai_knowledge_1")
# Relevant Columns
rel_col <- c("level_1", "level_2", "hard_1_1", "info_text", "level_3", "gender", "age", "license", "ai_knowledge_1")
df <- df[,rel_col]
View(df)
### TODO: REMOVE THIS FOR NON SIMULATED
df <- read_csv("e7_simulated.csv")
df <- df[-c(1,2),]
View(df)
df |>
filter(level_1 == "Yes") |>
select(level_1, level_2, hard_1_1, gender, age, license, ai_knowledge_1) -> found
View(found)
colnames(found) <- c("found", "level", "difficulty", "gender", "age", "license", "ai_knowledge")
df |>
filter(level_1 == "No") |>
select(level_1, level_3, hard_1_1, gender, age, license, ai_knowledge_1) -> not_found
View(df)
sum(is.na(df$level_1))
225+53+60
colnames(not_found) <- colnames(found)
View(not_found)
View(found)
df <- rbind(found, not_found)
rm(found, not_found)
View(df)
df$age <- sample(18:65, n, replace = T)
# TODO: Remove this lol
n <- len(df$age)
df$age <- sample(18:65, n, replace = T)
# TODO: Remove this lol
n <- len(df$age)
# TODO: Remove this lol
n <- length(df$age)
df$age <- sample(18:65, n, replace = T)
View(df)
colnames(found) <- c("found", "auto_level", "difficulty", "gender", "age", "license", "ai_knowledge")
df |>
filter(level_1 == "No") |>
select(level_1, level_3, hard_1_1, gender, age, license, ai_knowledge_1) -> not_found
colnames(not_found) <- colnames(found)
df <- rbind(found, not_found)
rm(found, not_found)
## ================================================================================================================
##                                 Harvard Business School, Ethical Iopelligence Lab
## ================================================================================================================
##                                DATA ANALYSIS | AV RESPONSIBILITY STUDY | EXPERIMEop 5
## ================================================================================================================
## clear workspace
rm(list = ls())
# libraries
library(sjstats)
library(tidyverse)
library(ggpubr)
library(ggsignif)
#source('../e2_liability/process.R')
# Read full dataset
df <- read_csv("e7_simulated.csv")
# Remove first two rows that were headers
df <- df[-c(1,2),]
#==============================================================
# EXCLUSIONS & DATA CLEANING
#==============================================================
## Failed Attention Checks
df |>
filter(
att_1 == "Paul",
att_2 == "Green") -> df
## Comprehension Checks
df |>
filter(
comp_1 == "Different types of vehicles based on how many driving tasks are controlled by humans vs. machines",
comp_2 == "HUMAN, HUMAN, HUMAN, HUMAN"
) -> df
## TODO: get prop is excluded
### TODO: REMOVE THIS FOR NON SIMULATED
df <- read_csv("e7_simulated.csv")
df <- df[-c(1,2),]
# Relevant Columns and Elongate Data
rel_col <- c("level_1", "level_2", "hard_1_1", "info_text", "level_3", "gender", "age", "license", "ai_knowledge_1")
df <- df[,rel_col]
df |>
filter(level_1 == "Yes") |>
select(level_1, level_2, hard_1_1, gender, age, license, ai_knowledge_1) -> found
colnames(found) <- c("found", "auto_level", "difficulty", "gender", "age", "license", "ai_knowledge")
df |>
filter(level_1 == "No") |>
select(level_1, level_3, hard_1_1, gender, age, license, ai_knowledge_1) -> not_found
colnames(not_found) <- colnames(found)
df <- rbind(found, not_found)
rm(found, not_found)
# TODO: Remove this lol
n <- length(df$age)
df$age <- sample(18:65, n, replace = T)
#==============================================================
# DEMOGRAPHICS
#==============================================================
View(df)
gsub("Level ", "", df$auto_level)
# But not this
df$auto_level <- gsub("Level ", "", df$auto_level)
View(df)
df$difficulty <- as.numeric(df$difficulty)
View(df)
df$ai_knowledge <- as.numeric(df$ai_knowledge)
View(df)
#==============================================================
# DEMOGRAPHICS
#==============================================================
## Age
mean(df$age, rm.na=T)
hist(df$age)
hist(df$age, main = "Age Distribution")
## Gender
male <- length(df[df$gender == "Male",])
## Gender
male <- length(df[df$gender == "Male",]$gender)
male
## Gender
male <- (df[df$gender == "Male",]$gender)
## Gender
male <- length(df[df$gender == "Male",]$gender)
female <- length(df[df$gender == "Female",]$gender)
## Gender
n_male <- length(df[df$gender == "Male",]$gender)
n_female <- length(df[df$gender == "Female",]$gender)
prop_female <- n_female / (n_male + n_female)
rm(n_male, n_female, prop_female)
## ================================================================================================================
##                                 Harvard Business School, Ethical Iopelligence Lab
## ================================================================================================================
##                                DATA ANALYSIS | AV RESPONSIBILITY STUDY | EXPERIMEop 5
## ================================================================================================================
## clear workspace
rm(list = ls())
function (x, df1, df2, ncp, log = FALSE)
{
if (missing(ncp))
.Call(C_df, x, df1, df2, log)
else .Call(C_dnf, x, df1, df2, ncp, log)
}
## ================================================================================================================
##                                 Harvard Business School, Ethical Iopelligence Lab
## ================================================================================================================
##                                DATA ANALYSIS | AV RESPONSIBILITY STUDY | EXPERIMEop 5
## ================================================================================================================
## clear workspace
rm(list = ls())
# libraries
library(sjstats)
library(tidyverse)
library(ggpubr)
library(ggsignif)
# Read full dataset
df <- read_csv("e7_simulated.csv")
# Remove first two rows that were headers
df <- df[-c(1,2),]
#==============================================================
# EXCLUSIONS & DATA CLEANING
#==============================================================
## Failed Attention Checks
df |>
filter(
att_1 == "Paul",
att_2 == "Green") -> df
## Comprehension Checks
df |>
filter(
comp_1 == "Different types of vehicles based on how many driving tasks are controlled by humans vs. machines",
comp_2 == "HUMAN, HUMAN, HUMAN, HUMAN"
) -> df
### TODO: REMOVE THIS FOR NON SIMULATED
df <- read_csv("e7_simulated.csv")
df <- df[-c(1,2),]
# Relevant Columns and Elongate Data
rel_col <- c("level_1", "level_2", "hard_1_1", "info_text", "level_3", "gender", "age", "license", "ai_knowledge_1")
df <- df[,rel_col]
df |>
filter(level_1 == "Yes") |>
select(level_1, level_2, hard_1_1, gender, age, license, ai_knowledge_1) -> found
colnames(found) <- c("found", "auto_level", "difficulty", "gender", "age", "license", "ai_knowledge")
df |>
filter(level_1 == "No") |>
select(level_1, level_3, hard_1_1, gender, age, license, ai_knowledge_1) -> not_found
colnames(not_found) <- colnames(found)
df <- rbind(found, not_found)
rm(found, not_found)
# TODO: Remove this lol
n <- length(df$age)
df$age <- sample(18:65, n, replace = T)
# But not this
df$auto_level <- as.numeric(gsub("Level ", "", df$auto_level))
df$difficulty <- as.numeric(df$difficulty)
df$ai_knowledge <- as.numeric(df$ai_knowledge)
#==============================================================
# DEMOGRAPHICS
#==============================================================
## Age
mean(df$age, rm.na=T)
hist(df$age, main = "Age Distribution")
## Gender
n_male <- length(df[df$gender == "Male",]$gender)
n_female <- length(df[df$gender == "Female",]$gender)
prop_female <- n_female / (n_male + n_female)
rm(n_male, n_female, prop_female)
## AI Knowledge
mean(df$ai_knowledge, rm.na=T)
hist(df$ai_knowledge)
hist(df$ai_knowledge, main = "Distribution of AI Knowledge")
View(df)
## License
table(df$license)
## License
prop.table(table(df$license))
setwd("/Users/jho/Dropbox (Harvard University)/Justin/Keywords")
library(readxl)
library(tidyverse)
library(readxl)
df <- read_csv("./1_Data/similarity.csv")
plot(df$p_tfidf_cs, df$p_word_cs)
df_flipped <- df
left <- df_flipped$left
df_flipped$left <- df_flipped$right
df_flipped$right <- left
df <- rbind(df, df_flipped)
colnames(df)[1] <- "ps_index"
colnames(df)[2] <- "paired"
df |>
group_by(ps_index, level) |>
summarize(
n = n()
) -> check
View(df)
summarize_at()
?summarize_at()
View(check)
View(df)
df |>
group_by(ps_index, level) |>
select(-paired) |>
summarise_if(is.numeric, mean, na.rm=TRUE)
df |>
group_by(ps_index, level) |>
select(-paired) |>
summarise_if(is.numeric, mean, na.rm=TRUE) -> df
rm(df_flipped)
rm(check)
master_file <- read_xlsx("./1_Data/similarity.xlsx")
master_file <- read_xlsx("./1_Data/circ_econ_eval_processed.xlsx")
View(master_file)
master_file |>
select(ps_index, quality, novelty, feasibility, envt_impact, fin_impact) |>
group_by(ps_index) |>
summarise_if(is.numeric, mean, na.rm=TRUE) -> master_file
master_file |>
select(ps_index, quality, novelty, feasibility, envt_impact, fin_impact) |>
group_by(ps_index) |>
summarise_if(is.numeric, mean, na.rm=TRUE) -> eval
rm(master_file)
View(eval)
df |>
left_join(eval, by = "ps_index") -> df
View(df)
View(df)
reg1 <- lm(quality ~ s_tfidf_cs, df)
summary(reg1)
reg2 <- lm(novelty ~ s_tfidf_cs, df)
summary(reg2)
reg2 <- lm(novelty ~ s_word_cs, df)
summary(reg2)
reg2 <- lm(novelty ~ s_tfidf_cs, df)
summary(reg2)
reg2 <- lm(novelty ~ s_tfidf_cs, df)
summary(reg2)
reg3 <- lm(novelty ~ s_tfidf_cs + level, df)
summary(reg2)
summary(reg3)
reg2.5 <- lm(novelty ~ level, df)
summary(reg2.5)
reg2.75 <- lm(s_tfidf_cs ~ level, df)
summary(reg2.75)
setwd("/Users/jho/Dropbox (Harvard University)/Justin/Keywords")
library(tidyverse)
library(readxl)
df <- read_csv("./1_Data/similarity.csv")
plot(df$p_tfidf_cs, df$p_word_cs)
library(stargazer)
View(df)
df <- read_csv("./1_Data/similarity.csv")
plot(df$p_tfidf_cs, df$p_word_cs)
df_flipped <- df
left <- df_flipped$left
df_flipped$left <- df_flipped$right
df_flipped$right <- left
df <- rbind(df, df_flipped)
rm(df_flipped)
colnames(df)[1] <- "ps_index"
colnames(df)[2] <- "paired"
df |>
group_by(ps_index, level) |>
select(-paired) |>
summarise_if(is.numeric, mean, na.rm=TRUE) -> df
master_file <- read_xlsx("./1_Data/circ_econ_eval_processed.xlsx")
master_file |>
select(ps_index, quality, novelty, feasibility, envt_impact, fin_impact) |>
group_by(ps_index) |>
summarise_if(is.numeric, mean, na.rm=TRUE) -> eval
rm(master_file)
df |>
left_join(eval, by = "ps_index") -> df
reg1 <- lm(quality ~ s_tfidf_cs, df)
summary(reg1)
reg2 <- lm(novelty ~ s_tfidf_cs, df)
summary(reg2)
df <- read_csv("./1_Data/similarity.csv")
plot(df$p_tfidf_cs, df$p_word_cs)
cor(df$p_tfidf_cs, df$p_word_cs)
cor(df$s_tfidf_cs, df$s_word_cs)
plot(df$s_tfidf_cs, df$s_word_cs)
df_flipped <- df
left <- df_flipped$left
df_flipped$left <- df_flipped$right
df_flipped$right <- left
df <- rbind(df, df_flipped)
rm(df_flipped)
colnames(df)[1] <- "ps_index"
colnames(df)[2] <- "paired"
df |>
group_by(ps_index, level) |>
select(-paired) |>
summarise_if(is.numeric, mean, na.rm=TRUE) -> df
master_file <- read_xlsx("./1_Data/circ_econ_eval_processed.xlsx")
master_file |>
select(ps_index, quality, novelty, feasibility, envt_impact, fin_impact) |>
group_by(ps_index) |>
summarise_if(is.numeric, mean, na.rm=TRUE) -> eval
rm(master_file)
df |>
left_join(eval, by = "ps_index") -> df
View(df)
reg1 <- lm(quality ~ s_tfidf_cs, df)
summary(reg1)
reg2 <- lm(novelty ~ s_tfidf_cs, df)
summary(reg2)
cor(df$p_tfidf_cs, df$s_tfidf_cs)
reg3 <- lm(novelty ~ s_tfidf_cs + level, df)
summary(reg3)
reg2.5 <- lm(novelty ~ level, df)
reg2.5 <- lm(novelty ~ level, df)
summary(reg2.5)
reg2 <- lm(novelty ~ s_tfidf_cs , df)
summary(reg2)
master_file <- read_xlsx("./1_Data/circ_econ_eval_processed.xlsx")
View(master_file)
View(master_file)
reg4 <- lm(novelty ~ as.factor(prolific_id), master_file)
View(reg4)
master_file$novelty_res <- reg4$residuals
View(master_file)
View(master_file)
master_file$novelty_res
master_file <- read_xlsx("./1_Data/circ_econ_eval_processed.xlsx")
master_file |>
select(ps_index, quality, novelty, feasibility, envt_impact, fin_impact) |>
group_by(ps_index) |>
summarise_if(is.numeric, mean, na.rm=TRUE) -> eval
View(eval)
reg3 <- lm(envt_impact ~ s_tfidf_cs, df)
summary(reg1)
summary(reg3)
reg4 <- lm(fin_impact ~ s_tfidf_cs, df)
summary(reg4)
View(master_file)
colnames(master_file)
reg4 <- lm(feasibility ~ s_tfidf_cs, df)
summary(reg4)
reg4 <- lm(feasibility ~ s_tfidf_cs, df)
summary(reg4)
View(eval)
df |>
left_join(eval, by = "ps_index") -> df
View(df)
write.csv(df, "./1_Data/evaluation.csv", row.names = F)
library(tidyverse)
library(readxl)
library(stargazer)
df <- read_csv("./1_Data/similarity.csv")
plot(df$s_tfidf_cs, df$s_word_cs)
df_flipped <- df
left <- df_flipped$left
df_flipped$left <- df_flipped$right
df_flipped$right <- left
df <- rbind(df, df_flipped)
rm(df_flipped)
colnames(df)[1] <- "ps_index"
colnames(df)[2] <- "paired"
df |>
group_by(ps_index, level) |>
select(-paired) |>
summarise_if(is.numeric, mean, na.rm=TRUE) -> df
master_file <- read_xlsx("./1_Data/circ_econ_eval_processed.xlsx")
master_file |>
select(ps_index, quality, novelty, feasibility, envt_impact, fin_impact) |>
group_by(ps_index) |>
summarise_if(is.numeric, mean, na.rm=TRUE) -> eval
rm(master_file)
df |>
left_join(eval, by = "ps_index") -> df
View(df)
write.csv(df, "./1_Data/evaluation.csv", row.names = F)
setwd("/Users/jho/Dropbox (Harvard University)/av_mislabeling_liability")
