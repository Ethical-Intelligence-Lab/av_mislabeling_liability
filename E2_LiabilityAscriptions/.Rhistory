## number of participants AFTER exclusions:
n_final <- dim(d)[1] # extracting number of rows only, not columns
n_final
percent_excluded <- (n_original - n_final)/n_original
percent_excluded
table(d$cond)
##re-arrange data
d <- d %>% relocate(co_1, .after = auto_1)
d <- d %>% relocate(dr_1, .after = co_1)
d <- d %>% relocate(use_2_1_1, .after = use_1_1_1)
d <- d %>% relocate(use_3_1_1, .after = use_2_1_1)
d <- d %>% relocate(use_2_2_1, .after = use_1_2_1)
d <- d %>% relocate(use_3_2_1, .after = use_2_2_1)
d <- d %>% relocate(use_2_3_1, .after = use_1_3_1)
d <- d %>% relocate(use_3_3_1, .after = use_2_3_1)
d <- d %>% relocate(use_2_4_1, .after = use_1_4_1)
d <- d %>% relocate(use_3_4_1, .after = use_2_4_1)
d <- d %>% relocate(value_2_1_1, .after = value_1_1_1)
d <- d %>% relocate(value_3_1_1, .after = value_2_1_1)
d <- d %>% relocate(value_2_2_1, .after = value_1_2_1)
d <- d %>% relocate(value_3_2_1, .after = value_2_2_1)
d <- d %>% relocate(value_2_3_1, .after = value_1_3_1)
d <- d %>% relocate(value_3_3_1, .after = value_2_3_1)
d <- d %>% relocate(value_2_4, .after = value_1_4)
d <- d %>% relocate(value_3_4, .after = value_2_4)
colnames(d)
## new data frame to extract pre-processed data into:
d_subset <- array(dim=c(dim(d)[1], 10))
colnames(d_subset) <- c('cond','auto','use1','use2','use3','use4','value1','value2','value3','value4')
d_subset <- as.data.frame(d_subset, stringsAsFactors=FALSE)
## extract data of interest from middle part of raw data:
for(i in 1:dim(d)[1]) {
curr <- d[i,24:26][!is.na(d[i,24:26])] # for a given row, get only the non-NA values
d_subset[i,2] <- as.numeric(curr[curr!= ""]) # and only the non-empty values
u1 <- d[i,27:29][!is.na(d[i,27:29])]
d_subset[i,3] <- as.numeric(u1[u1!= ""])
u2 <- d[i,30:32][!is.na(d[i,30:32])]
d_subset[i,4] <- as.numeric(u2[u2!= ""])
u3 <- d[i,33:35][!is.na(d[i,33:35])]
d_subset[i,5] <- as.numeric(u3[u3!= ""])
u4 <- d[i,36:38][!is.na(d[i,36:38])]
d_subset[i,6] <- as.numeric(u4[u4!= ""])
v1 <- d[i,39:41][!is.na(d[i,39:41])]
d_subset[i,7] <- as.numeric(v1[v1!= ""])
v2 <- d[i,42:44][!is.na(d[i,42:44])]
d_subset[i,8] <- as.numeric(v2[v2!= ""])
v3 <- d[i,45:47][!is.na(d[i,45:47])]
d_subset[i,9] <- as.numeric(v3[v3!= ""])
v4 <- d[i,48:50][!is.na(d[i,48:50])]
d_subset[i,10] <- as.numeric(v4[v4!= ""])
d_subset[i,1] <- d[i,61][!is.na(d[i,61])]
}
## merge data of interest back with raw data:
# new data frame to work with
d_merged <- cbind(d_subset, d[,51:60])
d_merged$ss <- 1:dim(d_merged)[1]
colnames(d_merged)
## cleaning up extreme prices of $30, $50 and $480,000
d_merged$value4
d_merged <- d_merged[-98,] #50
d_merged <- d_merged[-102,] #30
d_merged <- d_merged[-60,] #480k
rm(d, d_subset, i, curr)
## age
mean_age <- mean(d_merged$age, trim = 0, na.rm = TRUE) ## mean age
mean_age
hist(d_merged$age)
## gender
prop_male <- table(d_merged$gender)[[1]]/sum(table(d_merged$gender)) ## percentage of males
prop_male
prop_female <- table(d_merged$gender)[[2]]/sum(table(d_merged$gender)) ## percentage of females
prop_female
# LEVEL OF AUTOMATION
# t-tests
## Autopilot vs Copilot
d1 <- subset(d_merged, d_merged$cond != 'dless')
t.test(auto ~ cond, data = d1)
## Autopilot vs Driverless
d2 <- subset(d_merged, d_merged$cond != 'co')
t.test(auto ~ cond, data = d2)
## Copilot vs. Driverless
d3 <- subset(d_merged, d_merged$cond != 'auto')
t.test(auto ~ cond, data = d3)
# Standard Deviation
## Driverless
sd(d_merged[d_merged$cond == "dless",]$auto)
## Autopilot
sd(d_merged[d_merged$cond == "auto",]$auto)
## Copilot
sd(d_merged[d_merged$cond == "co",]$auto)
setwd("/Users/jho/Dropbox (Harvard University)/Julian/av_mislabeling_liability/E2_LiabilityAscriptions")
## ================================================================================================================
##                                 Harvard Business School, Ethical Intelligence Lab
## ================================================================================================================
##                                DATA ANALYSIS | AV responsibility STUDY | EXPERIMENT 4
## ================================================================================================================
## clear workspace
rm(list = ls())
## install packages
library(ggpubr)
library(dplyr)
library(grid)
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load('ggplot2',         # plotting
'ggsignif',        # plotting significance bars
'lme4',            # functions for fitting linear regression models
'ggforce',         # make ggplot even fancier
'ggpubr',          # arrange plots in a grid, if needed
'ltm',             # probably not using..
'tidyr',           # tools for cleaning messy data
'stringr',         # perform string substitutions easily
'assertthat',      # allows me to check whether a variable is a string, with is.string
'emmeans',         # contrast analysis for regression models
'stats',           # use function to adjust for multiple comparisons
'filesstrings',    # create and move files
'simr',            # power analysis for mixed models
'compute.es',      # effect size package
'effsize',         # another effect size package
'pwr',             # package for power calculation
'nlme',            # get p values for mixed effect model
'DescTools',        # get Cramer's V
'rstatix',
'effects'
)
## read in data
d <- read.csv('data.csv')
source("../process.R")
## rename colnames
## and change condition entries
d |>
rename(
cond = FL_12_DO,
auto_resp_human = resp_human1_10,
auto_resp_software = resp_software1_10,
co_resp_human = resp_human2_10,
co_resp_software = resp_software2_10,
auto_liab_human = liable_human1_1,
auto_liab_firm = liable_firm1_1,
co_liab_human = liab_human2_1,
co_liab_firm = liab_firm2_1,
) |>
mutate(cond = ifelse(cond == "FL_35", "auto", "co")) -> d
## subjects randomized:
table(d$cond)
## number of participants BEFORE exclusions:
num_participants <- dim(d)[1]
num_participants
## attention exclusions:
# remove responses from data frame that failed attention checks
d <- subset(d, (d$att_1 == 2 & d$att_2 == 2))
n_original <- dim(d)[1]
n_original
## comprehension exclusions:
# remove responses from data frame that failed comprehension checks
d <- subset(d, (d$comp_1 == 2 & d$comp_2 == 4))
dim(d)[[1]] # number of participants should decrease after comprehension exclusions
d <- subset(d, (d$comp_3 == 2 | d$comp_4 == 1))
dim(d)[[1]]
## incomplete responses
d <- subset(d, (d$Finished == 1))
## number of participants AFTER exclusions:
n_final <- dim(d)[[1]] # extracting number of rows only, not columns
n_final
percent_excluded <- (n_original - n_final)/n_original
percent_excluded
table(d$cond)
colnames(d)
d <- d %>% relocate(co_1, .after = auto_1)
d <- d %>% relocate(co_resp_software, .after = auto_resp_software)
d <- d %>% relocate(co_resp_human, .after = auto_resp_human)
d <- d %>% relocate(co_liab_firm, .after = auto_liab_firm)
d <- d %>% relocate(co_liab_human, .after = auto_liab_human)
## new data frame to extract pre-processed data into:
d_subset <- array(dim=c(dim(d)[1], 6))
colnames(d_subset) <- c('cond','automation','software responsibility','human responsibility','firm liability','human liability')
d_subset <- as.data.frame(d_subset, stringsAsFactors=FALSE)
## extract data of interest from middle part of raw data:
for(i in 1:dim(d)[1]) {
pref1 <- d[i,23:24][!is.na(d[i,23:24])] # for a given row, get only the non-NA values
d_subset[i,2] <- as.numeric(pref1[pref1!= ""]) # and only the non-empty values
resp1 <- d[i,25:26][!is.na(d[i,25:26])]
d_subset[i,3] <- as.numeric(resp1[resp1!= ""])
resp2 <- d[i,27:28][!is.na(d[i,27:28])]
d_subset[i,4] <- as.numeric(resp2[resp2!= ""])
liab1 <- d[i,29:30][!is.na(d[i,29:30])]
d_subset[i,5] <- as.numeric(liab1[liab1!= ""])
liab2 <- d[i,31:32][!is.na(d[i,31:32])]
d_subset[i,6] <- as.numeric(liab2[liab2!= ""])
d_subset[i,1] <- d[i,49][!is.na(d[i,49])]
}
## merge data of interest back with raw data:
# new data frame to work with
d_merged <- cbind(d_subset, d[,38:46])
d_merged$ss <- 1:dim(d_merged)[1]
colnames(d_merged)
## age
mean(d_merged$age, trim = 0, na.rm = TRUE) ## mean age
hist(d_merged$age, main = "Histogram of Age", xlab = "Age")
## gender
gender <- ifelse(d$gender == 1, "Male", "Female")
g_table <- table(gender)
g_table
prop_gtable <- prop.table(g_table)
prop_gtable
rm(d, d_subset)
# Cronbach Alpha of Human and Firm Measure
cronbach.alpha(d_merged[,c("software responsibility", "firm liability")])
cronbach.alpha(d_merged[,c("human responsibility", "human liability")])
# Create composite measure and make condition as factor
d_merged |>
mutate(firm = (`software responsibility` + `firm liability`) / 2,
human = (`human responsibility` + `human liability`) / 2,
cond = as.factor(cond)) -> d_merged
# t-tests
## Perceived Level of Automation
t.test(automation ~ cond, d_merged)
sd(d_merged[d_merged$cond == "auto",]$automation)
sd(d_merged[d_merged$cond == "co",]$automation)
sd(d_merged[d_merged$cond == "auto",]$human)
sd(d_merged[d_merged$cond == "co",]$human)
sd(d_merged[d_merged$cond == "auto",]$firm)
sd(d_merged[d_merged$cond == "co",]$firm)
sd(d_merged[d_merged$cond == "auto",]$human)
sd(d_merged[d_merged$cond == "co",]$human)
## ================================================================================================================
##                                 Harvard Business School, Ethical Intelligence Lab
## ================================================================================================================
##                                DATA ANALYSIS | AV responsibility STUDY | EXPERIMENT 4
## ================================================================================================================
## clear workspace
rm(list = ls())
## install packages
library(ggpubr)
library(dplyr)
library(grid)
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load('ggplot2',         # plotting
'ggsignif',        # plotting significance bars
'lme4',            # functions for fitting linear regression models
'ggforce',         # make ggplot even fancier
'ggpubr',          # arrange plots in a grid, if needed
'ltm',             # probably not using..
'tidyr',           # tools for cleaning messy data
'stringr',         # perform string substitutions easily
'assertthat',      # allows me to check whether a variable is a string, with is.string
'emmeans',         # contrast analysis for regression models
'stats',           # use function to adjust for multiple comparisons
'filesstrings',    # create and move files
'simr',            # power analysis for mixed models
'compute.es',      # effect size package
'effsize',         # another effect size package
'pwr',             # package for power calculation
'nlme',            # get p values for mixed effect model
'DescTools',        # get Cramer's V
'rstatix',
'effects'
)
## read in data
d <- read.csv('data.csv')
source("../process.R")
## rename colnames
## and change condition entries
d |>
rename(
cond = FL_12_DO,
auto_resp_human = resp_human1_10,
auto_resp_software = resp_software1_10,
co_resp_human = resp_human2_10,
co_resp_software = resp_software2_10,
auto_liab_human = liable_human1_1,
auto_liab_firm = liable_firm1_1,
co_liab_human = liab_human2_1,
co_liab_firm = liab_firm2_1,
) |>
mutate(cond = ifelse(cond == "FL_35", "auto", "co")) -> d
## subjects randomized:
table(d$cond)
## number of participants BEFORE exclusions:
num_participants <- dim(d)[1]
num_participants
## attention exclusions:
# remove responses from data frame that failed attention checks
d <- subset(d, (d$att_1 == 2 & d$att_2 == 2))
n_original <- dim(d)[1]
n_original
## comprehension exclusions:
# remove responses from data frame that failed comprehension checks
d <- subset(d, (d$comp_1 == 2 & d$comp_2 == 4))
dim(d)[[1]] # number of participants should decrease after comprehension exclusions
d <- subset(d, (d$comp_3 == 2 | d$comp_4 == 1))
dim(d)[[1]]
## incomplete responses
d <- subset(d, (d$Finished == 1))
## number of participants AFTER exclusions:
n_final <- dim(d)[[1]] # extracting number of rows only, not columns
n_final
percent_excluded <- (n_original - n_final)/n_original
percent_excluded
table(d$cond)
colnames(d)
d <- d %>% relocate(co_1, .after = auto_1)
d <- d %>% relocate(co_resp_software, .after = auto_resp_software)
d <- d %>% relocate(co_resp_human, .after = auto_resp_human)
d <- d %>% relocate(co_liab_firm, .after = auto_liab_firm)
d <- d %>% relocate(co_liab_human, .after = auto_liab_human)
## new data frame to extract pre-processed data into:
d_subset <- array(dim=c(dim(d)[1], 6))
colnames(d_subset) <- c('cond','automation','software responsibility','human responsibility','firm liability','human liability')
d_subset <- as.data.frame(d_subset, stringsAsFactors=FALSE)
## extract data of interest from middle part of raw data:
for(i in 1:dim(d)[1]) {
pref1 <- d[i,23:24][!is.na(d[i,23:24])] # for a given row, get only the non-NA values
d_subset[i,2] <- as.numeric(pref1[pref1!= ""]) # and only the non-empty values
resp1 <- d[i,25:26][!is.na(d[i,25:26])]
d_subset[i,3] <- as.numeric(resp1[resp1!= ""])
resp2 <- d[i,27:28][!is.na(d[i,27:28])]
d_subset[i,4] <- as.numeric(resp2[resp2!= ""])
liab1 <- d[i,29:30][!is.na(d[i,29:30])]
d_subset[i,5] <- as.numeric(liab1[liab1!= ""])
liab2 <- d[i,31:32][!is.na(d[i,31:32])]
d_subset[i,6] <- as.numeric(liab2[liab2!= ""])
d_subset[i,1] <- d[i,49][!is.na(d[i,49])]
}
## merge data of interest back with raw data:
# new data frame to work with
d_merged <- cbind(d_subset, d[,38:46])
d_merged$ss <- 1:dim(d_merged)[1]
colnames(d_merged)
## age
mean(d_merged$age, trim = 0, na.rm = TRUE) ## mean age
hist(d_merged$age, main = "Histogram of Age", xlab = "Age")
## gender
gender <- ifelse(d$gender == 1, "Male", "Female")
g_table <- table(gender)
g_table
prop_gtable <- prop.table(g_table)
prop_gtable
rm(d, d_subset)
# Cronbach Alpha of Human and Firm Measure
cronbach.alpha(d_merged[,c("software responsibility", "firm liability")])
cronbach.alpha(d_merged[,c("human responsibility", "human liability")])
prop_gtable
## age
mean(d_merged$age, trim = 0, na.rm = TRUE) ## mean age
# Cronbach Alpha of Human and Firm Measure
cronbach.alpha(d_merged[,c("software responsibility", "firm liability")])
cronbach.alpha(d_merged[,c("human responsibility", "human liability")])
# Create composite measure and make condition as factor
d_merged |>
mutate(firm = (`software responsibility` + `firm liability`) / 2,
human = (`human responsibility` + `human liability`) / 2,
cond = as.factor(cond)) -> d_merged
# t-tests
## Perceived Level of Automation
t.test(automation ~ cond, d_merged)
sd(d_merged[d_merged$cond == "auto",]$automation)
sd(d_merged[d_merged$cond == "co",]$automation)
cohen.d(d_merged[d_merged$cond == "auto",]$automation,
d_merged[d_merged$cond == "co",]$automation)
## Human Liability
t.test(human ~ cond, d_merged)
## Firm Liability
t.test(firm ~ cond, d_merged)
sd(d_merged[d_merged$cond == "auto",]$firm)
sd(d_merged[d_merged$cond == "co",]$firm)
## ================================================================================================================
##                                 Harvard Business School, Ethical Intelligence Lab
## ================================================================================================================
##                                DATA ANALYSIS | AV responsibility STUDY | EXPERIMENT 4
## ================================================================================================================
## clear workspace
rm(list = ls())
## install packages
library(ggpubr)
library(dplyr)
library(grid)
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load('ggplot2',         # plotting
'ggsignif',        # plotting significance bars
'lme4',            # functions for fitting linear regression models
'ggforce',         # make ggplot even fancier
'ggpubr',          # arrange plots in a grid, if needed
'ltm',             # probably not using..
'tidyr',           # tools for cleaning messy data
'stringr',         # perform string substitutions easily
'assertthat',      # allows me to check whether a variable is a string, with is.string
'emmeans',         # contrast analysis for regression models
'stats',           # use function to adjust for multiple comparisons
'filesstrings',    # create and move files
'simr',            # power analysis for mixed models
'compute.es',      # effect size package
'effsize',         # another effect size package
'pwr',             # package for power calculation
'nlme',            # get p values for mixed effect model
'DescTools',        # get Cramer's V
'rstatix',
'effects'
)
## read in data
d <- read.csv('data.csv')
source("../process.R")
## rename colnames
## and change condition entries
d |>
rename(
cond = FL_12_DO,
auto_resp_human = resp_human1_10,
auto_resp_software = resp_software1_10,
co_resp_human = resp_human2_10,
co_resp_software = resp_software2_10,
auto_liab_human = liable_human1_1,
auto_liab_firm = liable_firm1_1,
co_liab_human = liab_human2_1,
co_liab_firm = liab_firm2_1,
) |>
mutate(cond = ifelse(cond == "FL_35", "auto", "co")) -> d
## subjects randomized:
table(d$cond)
## number of participants BEFORE exclusions:
num_participants <- dim(d)[1]
num_participants
## attention exclusions:
# remove responses from data frame that failed attention checks
d <- subset(d, (d$att_1 == 2 & d$att_2 == 2))
n_original <- dim(d)[1]
n_original
## comprehension exclusions:
# remove responses from data frame that failed comprehension checks
d <- subset(d, (d$comp_1 == 2 & d$comp_2 == 4))
dim(d)[[1]] # number of participants should decrease after comprehension exclusions
d <- subset(d, (d$comp_3 == 2 | d$comp_4 == 1))
dim(d)[[1]]
## incomplete responses
d <- subset(d, (d$Finished == 1))
## number of participants AFTER exclusions:
n_final <- dim(d)[[1]] # extracting number of rows only, not columns
n_final
percent_excluded <- (n_original - n_final)/n_original
percent_excluded
table(d$cond)
colnames(d)
d <- d %>% relocate(co_1, .after = auto_1)
d <- d %>% relocate(co_resp_software, .after = auto_resp_software)
d <- d %>% relocate(co_resp_human, .after = auto_resp_human)
d <- d %>% relocate(co_liab_firm, .after = auto_liab_firm)
d <- d %>% relocate(co_liab_human, .after = auto_liab_human)
## new data frame to extract pre-processed data into:
d_subset <- array(dim=c(dim(d)[1], 6))
colnames(d_subset) <- c('cond','automation','software responsibility','human responsibility','firm liability','human liability')
d_subset <- as.data.frame(d_subset, stringsAsFactors=FALSE)
## extract data of interest from middle part of raw data:
for(i in 1:dim(d)[1]) {
pref1 <- d[i,23:24][!is.na(d[i,23:24])] # for a given row, get only the non-NA values
d_subset[i,2] <- as.numeric(pref1[pref1!= ""]) # and only the non-empty values
resp1 <- d[i,25:26][!is.na(d[i,25:26])]
d_subset[i,3] <- as.numeric(resp1[resp1!= ""])
resp2 <- d[i,27:28][!is.na(d[i,27:28])]
d_subset[i,4] <- as.numeric(resp2[resp2!= ""])
liab1 <- d[i,29:30][!is.na(d[i,29:30])]
d_subset[i,5] <- as.numeric(liab1[liab1!= ""])
liab2 <- d[i,31:32][!is.na(d[i,31:32])]
d_subset[i,6] <- as.numeric(liab2[liab2!= ""])
d_subset[i,1] <- d[i,49][!is.na(d[i,49])]
}
## merge data of interest back with raw data:
# new data frame to work with
d_merged <- cbind(d_subset, d[,38:46])
d_merged$ss <- 1:dim(d_merged)[1]
colnames(d_merged)
## age
mean(d_merged$age, trim = 0, na.rm = TRUE) ## mean age
hist(d_merged$age, main = "Histogram of Age", xlab = "Age")
## gender
gender <- ifelse(d$gender == 1, "Male", "Female")
g_table <- table(gender)
g_table
prop_gtable <- prop.table(g_table)
prop_gtable
rm(d, d_subset)
# Cronbach Alpha of Human and Firm Measure
cronbach.alpha(d_merged[,c("software responsibility", "firm liability")])
cronbach.alpha(d_merged[,c("human responsibility", "human liability")])
# Create composite measure and make condition as factor
d_merged |>
mutate(firm = (`software responsibility` + `firm liability`) / 2,
human = (`human responsibility` + `human liability`) / 2,
cond = as.factor(cond)) -> d_merged
# t-tests
## Perceived Level of Automation
t.test(automation ~ cond, d_merged)
sd(d_merged[d_merged$cond == "auto",]$automation)
sd(d_merged[d_merged$cond == "co",]$automation)
sd(d_merged[d_merged$cond == "auto",]$firm)
sd(d_merged[d_merged$cond == "co",]$firm)
cohen.d(d_merged[d_merged$cond == "auto",]$firm,
d_merged[d_merged$cond == "co",]$firm)
## Human Liability
t.test(human ~ cond, d_merged)
sd(d_merged[d_merged$cond == "auto",]$human)
sd(d_merged[d_merged$cond == "co",]$human)
cohen.d(d_merged[d_merged$cond == "auto",]$human,
d_merged[d_merged$cond == "co",]$human)
## ================================================================================================================
##                                          MEDIATION ANALYSIS
## ================================================================================================================
d_merged$cond <- as.numeric(d_merged$cond)
process(data = d_merged, y = "human", x = "cond",
m =c("automation"), model = 4, effsize = 1, total = 1, stand = 1,
contrast =1, boot = 10000 , modelbt = 1, seed = 654321)
process(data = d_merged, y = "firm", x = "cond",
m =c("automation"), model = 4, effsize = 1, total = 1, stand = 1,
contrast =1, boot = 10000 , modelbt = 1, seed = 654321)
